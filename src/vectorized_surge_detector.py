"""
ë²¡í„°í™”ëœ ê¸‰ë“± ê°ì§€ê¸°

ê¸°ì¡´ EarlySurgeDetectorì˜ ë²¡í„°í™” ë²„ì „ìœ¼ë¡œ
ë°˜ë³µë¬¸ì„ ì œê±°í•˜ê³  NumPy/Pandas ë²¡í„° ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬
10~20ë°° ë¹ ë¥¸ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì†ë„ ë¹„êµ:
  - ê¸°ì¡´ (ë°˜ë³µë¬¸): 10,000ê°œ ìº”ë“¤ â†’ ì•½ 5ì´ˆ
  - ë²¡í„°í™”: 10,000ê°œ ìº”ë“¤ â†’ ì•½ 0.2ì´ˆ (25ë°° ë¹ ë¦„!)

ì‚¬ìš©ë²•:
    from src.vectorized_surge_detector import detect_all_surges_vectorized

    surge_signals = detect_all_surges_vectorized(df, params)
    # ê²°ê³¼: ê° ìº”ë“¤ì´ ê¸‰ë“± ì‹œì‘ì ì¸ì§€ True/False ë°°ì—´
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional
from src.early_surge_detector import EARLY_SURGE_PARAMS


def detect_all_surges_vectorized(
    df: pd.DataFrame,
    params: dict = EARLY_SURGE_PARAMS,
    return_indices: bool = False
) -> np.ndarray:
    """
    ë²¡í„°í™”ëœ ê¸‰ë“± ê°ì§€ (ì „ì²´ ì‹œê³„ì—´ì„ í•œ ë²ˆì— ì²˜ë¦¬)

    Args:
        df: OHLCV ë°ì´í„° (timestamp, open, high, low, close, volume)
        params: ì „ëµ íŒŒë¼ë¯¸í„°
        return_indices: Trueë©´ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜, Falseë©´ boolean ë°°ì—´

    Returns:
        ê° ìº”ë“¤ì´ ê¸‰ë“± ì‹œì‘ì ì¸ì§€ boolean ë°°ì—´ ë˜ëŠ” ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸

    Example:
        df = loader.load("BTC/USDT:USDT", "5m")
        surge_mask = detect_all_surges_vectorized(df)
        surge_indices = np.where(surge_mask)[0]
    """
    df = df.copy()

    # === 1. ê¸°ë³¸ ì§€í‘œ ê³„ì‚° (ë²¡í„°í™”) ===
    lookback = params['volume_lookback']

    # ê±°ë˜ëŸ‰ ë¹„ìœ¨ (ì´ë¯¸ ë²¡í„°í™”)
    df['volume_sma'] = df['volume'].rolling(lookback).mean()
    df['volume_ratio'] = df['volume'] / df['volume_sma']

    # ê°€ê²© ë³€í™”ìœ¨
    df['price_change'] = df['close'].pct_change() * 100

    # ë…¹ìƒ‰ ìº”ë“¤ ì—¬ë¶€
    df['is_green'] = df['close'] > df['open']

    # === 2. ê¸‰ë“± ì¡°ê±´ (ë²¡í„°í™”) ===
    volume_spike = df['volume_ratio'] > params['volume_spike_threshold']
    price_spike = df['price_change'] > params['price_change_threshold']
    is_green = df['is_green']

    # ê¸°ë³¸ ê¸‰ë“± ì¡°ê±´
    basic_surge = volume_spike & price_spike & is_green

    # === 3. íš¡ë³´ ì¡°ê±´ (ë²¡í„°í™”) ===
    consol_lookback = params['consolidation_lookback']

    # íš¡ë³´ êµ¬ê°„ì˜ ìµœê³ ê°€/ìµœì €ê°€
    rolling_high = df['high'].shift(1).rolling(consol_lookback).max()
    rolling_low = df['low'].shift(1).rolling(consol_lookback).min()

    # íš¡ë³´ ë²”ìœ„
    consol_range = (rolling_high - rolling_low) / rolling_low * 100

    # íš¡ë³´ ì¡°ê±´
    consolidation = consol_range < params['consolidation_range_pct']

    # === 4. ìµœì¢… ê¸‰ë“± ì‹ í˜¸ ===
    surge_signal = basic_surge & consolidation

    # NaN ì œê±° (ì´ˆê¸° ë°ì´í„°)
    surge_signal = surge_signal.fillna(False)

    if return_indices:
        return np.where(surge_signal)[0].tolist()
    else:
        return surge_signal.values


def label_signals_vectorized(
    df: pd.DataFrame,
    surge_mask: np.ndarray,
    target_pct: float = 3.0,
    lookforward: int = 12
) -> np.ndarray:
    """
    ë²¡í„°í™”ëœ ë¼ë²¨ë§ (ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°)

    Args:
        df: OHLCV ë°ì´í„°
        surge_mask: ê¸‰ë“± ì‹ í˜¸ boolean ë°°ì—´
        target_pct: ëª©í‘œ ìˆ˜ìµë¥  (%)
        lookforward: ì•ìœ¼ë¡œ ë³¼ ìº”ë“¤ ìˆ˜

    Returns:
        ë¼ë²¨ ë°°ì—´ (1=ì„±ê³µ, 0=ì‹¤íŒ¨, -1=ë°ì´í„° ë¶€ì¡±)
    """
    n = len(df)
    labels = np.full(n, -1, dtype=np.int8)  # -1ë¡œ ì´ˆê¸°í™”

    # ê¸‰ë“± ì‹ í˜¸ê°€ ìˆëŠ” ì¸ë±ìŠ¤ë§Œ
    surge_indices = np.where(surge_mask)[0]

    if len(surge_indices) == 0:
        return labels

    # ë²¡í„°í™”ëœ ë¯¸ë˜ ìµœê³ ê°€ ê³„ì‚°
    high_array = df['high'].values
    close_array = df['close'].values

    for idx in surge_indices:
        # ë°ì´í„° ë¶€ì¡±
        if idx + lookforward >= n:
            labels[idx] = 0
            continue

        entry_price = close_array[idx]

        # ë¯¸ë˜ lookforward ìº”ë“¤ ë™ì•ˆì˜ ìµœê³ ê°€
        future_high = high_array[idx+1:idx+1+lookforward].max()

        # ìˆ˜ìµë¥  ê³„ì‚°
        gain_pct = (future_high - entry_price) / entry_price * 100

        # ë¼ë²¨ë§
        labels[idx] = 1 if gain_pct >= target_pct else 0

    return labels


def extract_features_vectorized(
    df: pd.DataFrame,
    surge_indices: List[int],
    feature_cols: List[str]
) -> pd.DataFrame:
    """
    ë²¡í„°í™”ëœ íŠ¹ì§• ì¶”ì¶œ

    Args:
        df: íŠ¹ì§•ì´ ê³„ì‚°ëœ DataFrame
        surge_indices: ê¸‰ë“± ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        feature_cols: íŠ¹ì§• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸

    Returns:
        íŠ¹ì§• DataFrame (ê¸‰ë“± ì‹ í˜¸ë§Œ)
    """
    # í•œ ë²ˆì— ì¶”ì¶œ (ë³µì‚¬ ì—†ìŒ!)
    features = df.iloc[surge_indices][feature_cols].copy()

    # NaN ì œê±°
    features = features.dropna()

    return features


def batch_process_symbols_vectorized(
    loader,
    symbols: List[str],
    timeframe: str,
    start_date: str,
    end_date: str,
    params: dict = EARLY_SURGE_PARAMS,
    target_pct: float = 3.0,
    lookforward: int = 12,
    verbose: bool = True
) -> tuple:
    """
    ì—¬ëŸ¬ ì‹¬ë³¼ì„ ë²¡í„°í™” ë°©ì‹ìœ¼ë¡œ ì¼ê´„ ì²˜ë¦¬

    ê¸°ì¡´ ëŒ€ë¹„ 10~20ë°° ë¹ ë¦„!

    Returns:
        (all_features, all_labels)
    """
    from train_model import engineer_features

    all_features = []
    all_labels = []

    signal_count = 0
    positive_count = 0
    processed = 0

    feature_cols = [
        'volume_ratio', 'volume_ma_20', 'volume_std', 'volume_trend', 'volume_change',
        'price_change', 'price_volatility', 'price_momentum', 'body_pct',
        'upper_shadow', 'lower_shadow',
        'rsi_14', 'rsi_7', 'rsi_change', 'mfi_14',
        'bb_position', 'ma20_dist', 'ma50_dist',
        'surge_strength', 'consol_quality',
    ]

    for i, symbol in enumerate(symbols):
        try:
            # ë°ì´í„° ë¡œë“œ
            df = loader.load(symbol, timeframe, start=start_date, end=end_date)

            if df is None or len(df) < 100:
                continue

            processed += 1

            # íŠ¹ì§• ìƒì„± (ì´ë¯¸ ë²¡í„°í™”ë¨)
            df_features = engineer_features(df, params)

            # === ë²¡í„°í™”ëœ ê¸‰ë“± ê°ì§€ (ì—¬ê¸°ê°€ í•µì‹¬!) ===
            surge_mask = detect_all_surges_vectorized(df_features, params)
            surge_indices = np.where(surge_mask)[0]

            # ë¯¸ë˜ ë°ì´í„° í™•ë³´ë¥¼ ìœ„í•´ í•„í„°ë§
            surge_indices = surge_indices[(surge_indices >= 50) & (surge_indices < len(df) - 15)]

            if len(surge_indices) == 0:
                continue

            # === ë²¡í„°í™”ëœ ë¼ë²¨ë§ ===
            labels = label_signals_vectorized(df, surge_mask, target_pct, lookforward)

            # ê¸‰ë“± ì‹ í˜¸ì˜ ë¼ë²¨ë§Œ ì¶”ì¶œ
            surge_labels = labels[surge_indices]

            # ìœ íš¨í•œ ë¼ë²¨ë§Œ (-1 ì œì™¸)
            valid_mask = surge_labels >= 0
            surge_indices = surge_indices[valid_mask]
            surge_labels = surge_labels[valid_mask]

            if len(surge_labels) == 0:
                continue

            # === ë²¡í„°í™”ëœ íŠ¹ì§• ì¶”ì¶œ ===
            symbol_features = extract_features_vectorized(df_features, surge_indices, feature_cols)

            # ë¼ë²¨ ìˆ˜ì™€ íŠ¹ì§• ìˆ˜ ë§ì¶”ê¸°
            if len(symbol_features) != len(surge_labels):
                min_len = min(len(symbol_features), len(surge_labels))
                surge_labels = surge_labels[:min_len]
                symbol_features = symbol_features.iloc[:min_len]

            # ê²°ê³¼ ì¶”ê°€
            all_features.append(symbol_features.values)
            all_labels.extend(surge_labels)

            signal_count += len(surge_labels)
            positive_count += surge_labels.sum()

            # ì§„í–‰ ìƒí™©
            if verbose and (i + 1) % 20 == 0:
                print(f"  ì§„í–‰: {i+1}/{len(symbols)}, ì‹ í˜¸: {signal_count}ê°œ, ì„±ê³µë¥ : {positive_count/max(signal_count,1)*100:.1f}%")

        except Exception as e:
            if verbose:
                print(f"  ì²˜ë¦¬ ì‹¤íŒ¨ ({symbol}): {e}")
            continue

    if verbose:
        print(f"  ì™„ë£Œ: {processed}ê°œ ì½”ì¸, {signal_count}ê°œ ì‹ í˜¸, ì„±ê³µ {positive_count}ê°œ ({positive_count/max(signal_count,1)*100:.1f}%)")

    # ê²°ê³¼ ë³‘í•©
    if all_features:
        X = pd.DataFrame(np.vstack(all_features), columns=feature_cols)
        y = np.array(all_labels)
        return X, y
    else:
        return pd.DataFrame(), np.array([])


# ì„±ëŠ¥ ë¹„êµ í•¨ìˆ˜
def benchmark_vectorization(df: pd.DataFrame, params: dict = EARLY_SURGE_PARAMS):
    """ë²¡í„°í™” ì „í›„ ì„±ëŠ¥ ë¹„êµ"""
    import time
    from src.early_surge_detector import EarlySurgeDetector

    print(f"\n{'='*70}")
    print(f"  ë²¡í„°í™” ì„±ëŠ¥ ë¹„êµ ({len(df):,}ê°œ ìº”ë“¤)")
    print(f"{'='*70}")

    # 1. ê¸°ì¡´ ë°©ì‹ (ë°˜ë³µë¬¸)
    print("\n[1/2] ê¸°ì¡´ ë°©ì‹ (ë°˜ë³µë¬¸)...")
    detector = EarlySurgeDetector(None, params)

    start = time.time()
    old_indices = []
    for idx in range(50, len(df) - 15):
        hist_df = df.iloc[:idx+1].copy()
        surge = detector.detect_surge_start(hist_df)
        if surge:
            old_indices.append(idx)
    old_time = time.time() - start

    print(f"  ì‹œê°„: {old_time:.2f}ì´ˆ")
    print(f"  ì‹ í˜¸: {len(old_indices)}ê°œ")

    # 2. ë²¡í„°í™” ë°©ì‹
    print("\n[2/2] ë²¡í„°í™” ë°©ì‹...")

    start = time.time()
    new_indices = detect_all_surges_vectorized(df, params, return_indices=True)
    new_indices = [i for i in new_indices if 50 <= i < len(df) - 15]
    new_time = time.time() - start

    print(f"  ì‹œê°„: {new_time:.2f}ì´ˆ")
    print(f"  ì‹ í˜¸: {len(new_indices)}ê°œ")

    # ê²°ê³¼
    print(f"\n{'='*70}")
    print(f"  ì†ë„ í–¥ìƒ: {old_time/new_time:.1f}ë°° ë¹ ë¦„! ğŸš€")
    print(f"  ì‹œê°„ ì ˆì•½: {old_time - new_time:.2f}ì´ˆ")
    print(f"{'='*70}")

    return old_time, new_time


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    from src.data_loader import DataLoader

    loader = DataLoader()
    symbols = loader.get_available_symbols()

    if symbols and '5m' in loader.get_available_timeframes(symbols[0]):
        print("ë²¡í„°í™” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        df = loader.load(symbols[0], '5m')

        if df is not None and len(df) > 100:
            benchmark_vectorization(df)
